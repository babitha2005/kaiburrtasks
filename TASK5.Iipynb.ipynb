{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75316314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample shape: (200000, 18)\n",
      "  Date received                                            Product  \\\n",
      "0    2020-07-06  Credit reporting, credit repair services, or o...   \n",
      "1    2025-09-24  Credit reporting or other personal consumer re...   \n",
      "2    2019-12-26                        Credit card or prepaid card   \n",
      "3    2020-05-08  Credit reporting, credit repair services, or o...   \n",
      "4    2025-09-23  Credit reporting or other personal consumer re...   \n",
      "\n",
      "                                  Sub-product  \\\n",
      "0                            Credit reporting   \n",
      "1                            Credit reporting   \n",
      "2  General-purpose credit card or charge card   \n",
      "3                            Credit reporting   \n",
      "4                            Credit reporting   \n",
      "\n",
      "                                               Issue  \\\n",
      "0               Incorrect information on your report   \n",
      "1               Incorrect information on your report   \n",
      "2  Advertising and marketing, including promotion...   \n",
      "3               Incorrect information on your report   \n",
      "4               Incorrect information on your report   \n",
      "\n",
      "                                           Sub-issue  \\\n",
      "0                Information belongs to someone else   \n",
      "1                Information belongs to someone else   \n",
      "2  Confusing or misleading advertising about the ...   \n",
      "3                Information belongs to someone else   \n",
      "4                Information belongs to someone else   \n",
      "\n",
      "  Consumer complaint narrative  \\\n",
      "0                          NaN   \n",
      "1                          NaN   \n",
      "2                          NaN   \n",
      "3   These are not my accounts.   \n",
      "4                          NaN   \n",
      "\n",
      "                             Company public response  \\\n",
      "0  Company has responded to the consumer and the ...   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  Company has responded to the consumer and the ...   \n",
      "4                                                NaN   \n",
      "\n",
      "                                  Company State ZIP code Tags  \\\n",
      "0     Experian Information Solutions Inc.    FL    346XX  NaN   \n",
      "1  TRANSUNION INTERMEDIATE HOLDINGS, INC.    KS    67206  NaN   \n",
      "2       CAPITAL ONE FINANCIAL CORPORATION    CA    94025  NaN   \n",
      "3     Experian Information Solutions Inc.    NV    89030  NaN   \n",
      "4     Experian Information Solutions Inc.    CA    93630  NaN   \n",
      "\n",
      "  Consumer consent provided? Submitted via Date sent to company  \\\n",
      "0                      Other           Web           2020-07-06   \n",
      "1                        NaN           Web           2025-09-24   \n",
      "2       Consent not provided           Web           2019-12-26   \n",
      "3           Consent provided           Web           2020-05-08   \n",
      "4                        NaN           Web           2025-09-23   \n",
      "\n",
      "  Company response to consumer Timely response? Consumer disputed?  \\\n",
      "0      Closed with explanation              Yes                NaN   \n",
      "1                  In progress              Yes                NaN   \n",
      "2      Closed with explanation              Yes                NaN   \n",
      "3      Closed with explanation              Yes                NaN   \n",
      "4                  In progress              Yes                NaN   \n",
      "\n",
      "   Complaint ID  \n",
      "0       3730948  \n",
      "1      16152255  \n",
      "2       3477549  \n",
      "3       3642453  \n",
      "4      16077048  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"D:\\complaints.csv\", low_memory=False, nrows=200000)\n",
    "print(\"Sample shape:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c087c6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Consumer complaint narrative clean_text\n",
      "0                          NaN           \n",
      "1                          NaN           \n",
      "2                          NaN           \n",
      "3   These are not my accounts.    account\n",
      "4                          NaN           \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download NLTK resources if not already present\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize stopwords and stemmer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    try:\n",
    "        # Handle missing or non-string entries\n",
    "        if not isinstance(text, str):\n",
    "            return ''\n",
    "        # Lowercase\n",
    "        text = text.lower()\n",
    "        # Remove URLs\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        # Remove numbers\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        # Tokenize\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        # Remove stopwords\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        # Stemming\n",
    "        stemmed = [stemmer.stem(word) for word in tokens]\n",
    "        # Join back to string\n",
    "        return ' '.join(stemmed)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return ''\n",
    "\n",
    "# Apply cleaning to the complaint narrative column\n",
    "if 'Consumer complaint narrative' in df.columns:\n",
    "    df['clean_text'] = df['Consumer complaint narrative'].apply(clean_text)\n",
    "else:\n",
    "    print(\"Column 'Consumer complaint narrative' not found in DataFrame.\")\n",
    "\n",
    "# Check results\n",
    "print(df[['Consumer complaint narrative', 'clean_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88e866ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.92      1887\n",
      "           1       0.87      0.79      0.83       921\n",
      "           2       0.33      0.04      0.07        25\n",
      "           3       0.91      0.90      0.90       343\n",
      "\n",
      "    accuracy                           0.89      3176\n",
      "   macro avg       0.75      0.67      0.68      3176\n",
      "weighted avg       0.88      0.89      0.88      3176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Check for required column\n",
    "if 'Consumer complaint narrative' not in df.columns or 'Product' not in df.columns:\n",
    "    raise ValueError(\"Required columns not found in DataFrame.\")\n",
    "\n",
    "# Filter for target categories\n",
    "target_products = [\n",
    "    'Credit reporting, credit repair services, or other personal consumer reports',\n",
    "    'Debt collection',\n",
    "    'Consumer Loan',\n",
    "    'Mortgage'\n",
    "]\n",
    "df = df[df['Product'].isin(target_products)]\n",
    "df = df.dropna(subset=['Consumer complaint narrative'])\n",
    "\n",
    "# Map labels to numbers\n",
    "label_map = {\n",
    "    'Credit reporting, credit repair services, or other personal consumer reports': 0,\n",
    "    'Debt collection': 1,\n",
    "    'Consumer Loan': 2,\n",
    "    'Mortgage': 3\n",
    "}\n",
    "df['label'] = df['Product'].map(label_map)\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "# Text preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    try:\n",
    "        if not isinstance(text, str):\n",
    "            return ''\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        tokens = text.split()\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return ''\n",
    "df['clean_text'] = df['Consumer complaint narrative'].apply(clean_text)\n",
    "\n",
    "# Feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['clean_text']).toarray()\n",
    "y = df['label'].values\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train classifier\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ccf7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
